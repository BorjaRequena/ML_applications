{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning applications\n",
    "\n",
    "> Showcase of typical machine learning applications leveraging transfer learning for fast implementations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce some of hte most relevant applicaions of machine learning to various fields using typical academic datasets to illustrate the process. \n",
    "\n",
    "We leverage pre-trained models that have been trained in massive datasets for several hours in order to obtain our results. We fine-tune these models to work for our various specific tasks in order to speed up the training process by orders of magnitude and achieve state-of-the-art results. This technique is known as **transfer learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer vision\n",
    "\n",
    "Computer vision is one of the most successful fields of machine learning. While in other fields, such as natural language processing, the advanaces in machine learning have taken longer, machines have long shown super-human results in the field of computer vision. For instance, a [remarkable work](https://arxiv.org/ftp/arxiv/papers/1708/1708.09843.pdf) shows how deep learning can use retinal images to detect a patientâ€™s age, gender, smoking status and systolic blood pressure, as well as doing inference on several risk factors.\n",
    "\n",
    "In this section, we showcase some applications of machine learning to the field of computer vision. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image classification\n",
    "\n",
    "The first task that comes into mind when we talk about computer vision is image classification. It consists on predicting a certain label for a given image among all the possibilities. \n",
    "\n",
    "Here, we illustrate the process with a rather funny example in which we aim to classify dog images into their respective breeds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
    "                 get_items=get_image_files, \n",
    "                 splitter=RandomSplitter(seed=42),\n",
    "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
    "                 item_tfms=Resize(460),\n",
    "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "dls = pets.dataloaders(path/\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(nrows=1, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet50, metrics=error_rate).to_fp16()\n",
    "learn.fine_tune(6, freeze_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-label classification\n",
    "\n",
    "In image classificaiton we, sometimes, encounter applications in which, rather than assigning a single label to the image, we need to provide a list of labels. This is known as multi-label classification and it is typically applied in situations in which we need to enumerate certain categories that appear in the image. I find it pretty intuitive to understand these kinds of tasks with the analogy of a kid to who we ask \"what do you see in this image?\" and the kid enumerates every single thing in it: a tree, a dog, the sun, a lake, grass, a house, etc. \n",
    "\n",
    "To provide an example, we use the [PASCAL](http://host.robots.ox.ac.uk/pascal/VOC/) dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PASCAL_2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(r): return path/'train'/r['fname']\n",
    "def get_y(r): return r['labels'].split(' ')\n",
    "\n",
    "def splitter(df):\n",
    "    train = df.index[~df['is_valid']].tolist()\n",
    "    valid = df.index[df['is_valid']].tolist()\n",
    "    return train, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n",
    "                   splitter=splitter,\n",
    "                   get_x=get_x, \n",
    "                   get_y=get_y,\n",
    "                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\n",
    "dls = dblock.dataloaders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet50, metrics=[accuracy_multi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3, base_lr=3e-3, freeze_epochs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image segmentation\n",
    "In image classification we had to predict a class out of a whole image, e.g. telling whether there as a XXXXXX or a XXXXX in the image. In segmentation tasks we assign a label to each specific pixel in the image.\n",
    "\n",
    "This technique has numerious applications in various fields. For instance, in autonomous driving we have to tell which parts of the image are road, traffic signs, pedestrians, etc. On a completely different approach, in biomedical imaging, segmentation is used to tell which regions of a given tissue are affected by certain diseases, such as telling apart tumorous cells from healthy ones, among other applications. \n",
    "\n",
    "Here we will show a segmentation example using the [CamVid dataset](http://www0.cs.ucl.ac.uk/staff/G.Brostow/papers/Brostow_2009-PRL.pdf) for autonomous driving. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.CAMVID_TINY)\n",
    "dls = SegmentationDataLoaders.from_label_func(\n",
    "    path, bs=8, fnames = get_image_files(path/\"images\"),\n",
    "    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',\n",
    "    codes = np.loadtxt(path/'codes.txt', dtype=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(dls, resnet34)\n",
    "learn.fine_tune(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(max_n=6, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image regression\n",
    "\n",
    "The last computer vision application that we will illustrate is image regression. A regression task is characterized by assigning a real number to a sample. Hence, rather than assigning labels to the images, the model will provide a continuous value.\n",
    "\n",
    "These kinds of tasks can be used to, for instance, infer the temperature of the soil or other atmospherical properties from satelite images or to provide the coordinates of certain objects in the given images. \n",
    "\n",
    "To provide an example, we will use the [Biwi kinect head pose dataset](https://icu.ee.ethz.ch/research/datsets.html), in which we want to find the coordinates of the head location of people in different videos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.BIWI_HEAD_POSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\n",
    "def img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\n",
    "def get_ctr(f):\n",
    "    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n",
    "    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n",
    "    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n",
    "    return tensor([c1,c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biwi = DataBlock(blocks=(ImageBlock, PointBlock),\n",
    "                 get_items=get_image_files,\n",
    "                 get_y=get_ctr,\n",
    "                 splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n",
    "                 batch_tfms=[*aug_transforms(size=(240,320)), \n",
    "                             Normalize.from_stats(*imagenet_stats)])\n",
    "dls = biwi.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=9, figsize=(8,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = dls.one_batch()\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, y_range=(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(3, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results(ds_idx=1, nrows=3, figsize=(6,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural language processing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
